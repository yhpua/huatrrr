---
title: "General Overview"
description: |
  Definitions of key terms commonly used in biomedical research 
date: 07-14-2020
author:
  - name: SGH PT Dept
bibliography: bibliography.bib
categories:
 - p-values
 - confidence interval
 - measurement type
 - Bayesian inference
image: pval.jpg
---


```{r}
#| warning: false
#| echo: false
#| message: false
knitr::opts_chunk$set(echo = FALSE)
```



## Types of Measurement

Binary: Two-level variables, e.g., yes/no, present/absent, gender

Nominal: Non-ordered categorical variables, e.g., race, profession

Ordinal: Ordered categorical variables, e.g., pain severity, radiographical osteoarthritis (OA) severity ratings (no/mild/moderate/severe OA) 

Count: Discrete variable with integer values, e.g., Length of Stay, number of falls

Continuous: Numerical variable which takes a whole range of values, e.g., age, height, BMI

## Mean & SD
Mean: Arithmetic average

SD: Measure of spread

- Mathematically, $\surd$ of averaged squared difference of an observation from the mean

- Can be used to estimate the dispersion of a normally distributed _population_ 

- An estimate of the variability of the population from which the sample was drawn [@altman2005statistics]

- About 95% of observations of any distribution usually fall within the 2 standard deviation limits

Asymmetric data: SD$\times$ 2  > Mean 

<aside>
Use this rule-of-thumb when you don't have access to the raw data [@altman1996detecting]
</aside>

SE: Standard error is the SD of the sampling distribution of a statistic. 

- SE is used to infer about the range of plausible values for the *true*  (population) statistic. 



## Median & IQR
Median: Middle sorted value

- Value such that around $\frac{1}{2}$ of the values are below it and above it

<aside>
This holds for truly continuous data
</aside>


- May not divide sample into $\frac{1}{2}$ for "clumped" data

- Mean is better than the median when the distribution (i) contains heavy ties, (ii) is limited or well-behaved

IQR: Measure of spread

- Defined by Quartile$_{1}$ ($Q_1$) and Quartile$_{3}$ ($Q_3$) 

- Interval containing the middle $\frac{1}{2}$ of the sample 




## *P*-value
- *P*-value = Probability value

- Assuming that *H*$_{0}$ were true, what is the probability of obtaining a result (statistic) as or more extreme than our observed result? 

- If the  probability is low (often set at *P*<0.05), we have sufficient evidence to reject *H*$_{0}$ and accept *H*$_{1}$

- If the  probability is low, we fail to reject *H*$_{0}$ but we do not speak of accepting *H*$_{0}$. The *P*-value provides evidence against a *null* hypothesis, **never** evidence for something. 

- The *P*-value is influenced by sample size and effect size. Classical statistical testing does not consider clinical significance: Clinical relevance cannot be concluded from small *P*-values.   

<aside>
Use this [link](https://www.youtube.com/embed/vemZtEM63GY) if the video doesn't play
</aside>

<iframe width="560" height="315" src="https://www.youtube.com/embed/vemZtEM63GY" frameborder="0" allowfullscreen></iframe>

<aside>
If you have understood the concept of P-values, please give credit to Josh Starmer - not me!
</aside>


 

## Confidence Interval
- Range of values within which that the "true" (population) summary statistic (e.g., mean, correlation coefficient, or difference score) would plausibly lie. 

To interpret a 95% confidence interval,

- The wrong way: There is a 95% chance that the unknown true value lies within the interval 

- The rough way: We are 95% confident that the unknown true value lies within the interval

- The exact way: If we were to repeat experiment many times and to compute, in each experiment, a confidence interval for the summary statistic, 95% of these CIs would contain the true (population) value. Or, this confidence interval is computed by an algorithm that has a 95% probability of including the true value in repeated sampling.


<aside>
Use this [link](https://www.youtube.com/embed/TqOeMYtOc1w) if the video doesn't play
</aside>

<iframe width="560" height="315" src="https://www.youtube.com/embed/TqOeMYtOc1w" frameborder="0" allowfullscreen></iframe>

<aside>
If you have understood the concept of confidence interval, please give credit to [Josh Starmer](https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw) - not me!
</aside>

 

## Interpreting *P*-values and 95%CI. 
<style>
div.blue { background-color:#e6f0ff; border-radius: 0px; padding: 0px;}
</style>
<div class = "blue">
In general, the only way that a large P -value can be interpreted is for example "The study did not provide sufficient evidence for an effect." One cannot say "Because *P* = 0.70, we conclude the drug has no effect". Only when the corresponding confidence interval excludes both clinically significant benefit and harm can one make such a conclusion. A large *P*-value by itself merely means that a higher sample size is required to allow conclusions to be drawn
</div>

<aside>
Go to Frank Harrell's [DataMethods](https://discourse.datamethods.org/t/author-checklist/3407) for more details 
</aside>

<br>    
 

<iframe width="560" height="315" src="https://www.youtube.com/embed/PPD8lER8ju4" frameborder="0" allowfullscreen></iframe>

<aside>
Adriene Hill from [Crash Course](https://thecrashcourse.com/courses/statistics) explains how to interpret "large" P-values
</aside>


## *P-value*, Point Estimate, 95% CI  
The *P*-value   
This quantifies the evidence for a non-zero between-group difference. A large *P*-value, by itself, only suggests that we have insufficient evidence for a between-group difference. 

<aside>
Remember: absence of evidence may not represent evidence of absence. 
</aside>

The observed mean difference    
Appraise this estimate against the MCID value.     
*What we do know*: An individual-level MCID is almost always [**greater** than a group-level MCID](https://rapm.bmj.com/content/early/2022/03/31/rapm-2021-103331)     
*What we do not know*: how much greater is **greater**? 

<aside>
In the absence of data, Yonghao suggests 0.5*individual-level MCID. But how much we can trust this estimate?
</aside>


The 95% CI      
(Very) Loosely speaking, this represents the range of plausible values for the true between-group differences.   
Wide CI: there is great uncertainty about the true between-group differences   
Narrow CI: there is little uncertainty about the true between-group differences. When there is little uncertainty, the finding is almost always clinically relevant.

<aside>
Hence, it is possible to have a finding that is statistically non-significant but highly clinically relevant. 
</aside>


Example      
Findings   
We observed a between-group difference of 6 points on the ODI, with a corresponding *P*-value of 0.01 and a 95%CI of 1 to 12 points

Appraisal     
The *P*-value: We have evidence of a non-zero between-group difference   
The Point estimate: If we are willing to assume a group-level MCID of 6 points, the observed between-group difference is probably clinically meaningful    
The 95% CI: The wide 95%CI includes clinically trivial values; hence, there is uncertainty about the true between-group difference 

<aside>
We need to consider whether the 95%CI includes/excludes clinically trivial results. 
</aside>


Inference   
Whilst we have evidence that two groups are different on the ODI and the observed between-group difference appeared to be clinically meaningful, there is still uncertainty about the true between-group differences. 



::: l-body
| Findings              | Interpretation                                    |
|-----------------------|------------------------------------------------|
| P<0.05  | Evidence of a (non-zero) treatment difference/effect                |
| P>0.05  | Insufficient/No evidence of association (â‰  evidence of no treatment difference)[^1]           |
| (1) P<0.05; 95% CIs exclude trivial effects | Evidence of a clinically meaningful treatment difference|
| (2) P<0.05; 95% CIs exclude meaningful effects | Evidence of a treatment diff; however, this difference is not clinically meaningful|
| (3) P<0.05; 95% CIs include trivial + meaningful effects | Cannot exclude non-clinically meaningful treatment difference|
| (4) P>0.05; 95% CIs exclude meaningful effects  | (Possibly) Evidence of no treatment difference       |
| (5) P>0.05; 95% CI limits include meaningful effects  | CI indicates a wide range of plausible true treatment differences (inconclusive finding as all scenarios are possible)           |
| (6) P>0.05; 95% CI limits  include trivial + meaningful effects  | No evidence of treatment difference, however, we cannot exclude clinically important difference           |
:::

[^1]: Beware of making the "Absence of Evidence is NOT Evidence of Absence" fallacy


Hawkins and Samuels [JAMA article](https://jamanetwork.com/journals/jama/article-abstract/2786522) describes how to use 95%CIs to appraise non-significant results 
<br> 
![ci_ns](ci_ns.jpg){width=500}

Interestingly, the authors wrote:

> Although CIs can be used to enhance the interpretation of a study, they have a number of limitations. For example, a 95%CI does not have a 95% probability of containing the true value of interest (eg, the true treatment effect), **even though it is commonly described that way**. Creating an interval that does have a specified probability of containing the true value requires a Bayesian analysis  
>
> `r tufte::quote_footer('--- Hawkins and Samuels')`




## Bayesian Statistics
- A branch of statistics that (i) uses Bayes Theorem and (ii) doesn't use P-values and generally does not test hypotheses. 

- Bayesian Statistics requires one to formally specify a probability distribution encapsulating the prior knowledge about, say, a treatment effect. 

<aside>
This section is taken from Frank Harrell's [glossary](http://hbiostat.org/glossary/) 
</aside>

- The state of prior knowledge can be specified as $no$ knowledge" by using a flat distribution, although this can lead to
wild and nonsensical estimates. 
- Once the prior distribution is specified, the data are used to modify the prior state of knowledge to obtain the post-experiment state of knowledge. 
- Final probabilities computed in the Bayesian framework are probabilities of various treatment effects. 


### Comparing the 2 schools of thought
::: l-body
| Bayesian                           | Frequentist                                    |
|------------------------------------|------------------------------------------------|
| Bayesian statistics aims to uncover the unknown treatment effect by providing evidence for all its possible values |                                        Frequentist statistics aims to uncover the unknown treatment effect by providing evidence that it is not the null value|
| In Bayesian statistics, one specifies the prior distribution for the unknown treatment effect  and uses a data generation process to estimate the conditional data likelihood. For a given (single) data-set, Bayesian statistics provides probabilities for all possible values of the treatment effect|                              In Frequentist statistics, one specifies a null hypothesis/value about the unknown treatment effect and uses a data generation process to make infinite replications of the data. For a given null hypothesis, Frequentist statistics provides probabilities of getting studies/datasets with more extreme results than the ones that we observe. In other words, conditional on there being no treatment efficacy and no harm, the P-value is the proportion of studies with results more extreme than the ones we have
:::



<style>
div.blue { background-color:#e6f0ff; border-radius: 0px; padding: 0px;}
</style>
<div class = "blue">

Prof Frank Harrell has provided a more detailed side-by-side [comparison](https://hbiostat.org/proj/covid19/statdesign.html#bftable)

</div>




### Bayes Theorem
In my opinion, [3Blue1Brown](https://www.3blue1brown.com/) explains this the best

<br>    
<iframe width="560" height="315" src="https://www.youtube.com/embed/HZGCoVF3YvM" frameborder="0" allowfullscreen>
</iframe>

<br>    
<iframe width="560" height="315" src="https://www.youtube.com/embed/lG4VkPoG3ko" frameborder="0" allowfullscreen>
</iframe>


<aside>
Go to [Better Explained](https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/) for more details 
</aside>


### Consideration
- Bayesian methods provide direct, simply-stated probabilities of various treatment effects. 

- The price of being able to compute probabilities of various treatment effects is the necessity of specifying a prior
distribution to anchor the calculations.

- Tutorials for healthcare professionals 
    - [Baldwin and Larson 2017](https://pubmed.ncbi.nlm.nih.gov/28081861/) 
    - [Heino et al 2018](https://pubmed.ncbi.nlm.nih.gov/34040821/)
    - Frank Harrell's incredibly useful [hbiostat pages](https://hbiostat.org/bayes/)

    



## To Note {.appendix}
A comprehensive glossary of terms can be found [here](http://hbiostat.org/glossary/)

Statistical problems to avoid when reading an article can be found [here](https://discourse.datamethods.org/t/author-checklist/3407) 



