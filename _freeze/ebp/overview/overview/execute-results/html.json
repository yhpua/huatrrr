{
  "hash": "91b207b5031a6bdc3f0a59270d1a68d8",
  "result": {
    "markdown": "---\ntitle: \"General Overview\"\ndescription: |\n  Definitions of key terms commonly used in biomedical research \ndate: 07-14-2020\nauthor:\n  - name: SGH PT Dept\nbibliography: bibliography.bib\ncategories:\n - p-values\n - confidence interval\n - measurement type\n - Bayesian inference\nimage: pval.jpg\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n## Types of Measurement\n\nBinary: Two-level variables, e.g., yes/no, present/absent, gender\n\nNominal: Non-ordered categorical variables, e.g., race, profession\n\nOrdinal: Ordered categorical variables, e.g., pain severity, radiographical osteoarthritis (OA) severity ratings (no/mild/moderate/severe OA) \n\nCount: Discrete variable with integer values, e.g., Length of Stay, number of falls\n\nContinuous: Numerical variable which takes a whole range of values, e.g., age, height, BMI\n\n## Mean & SD\nMean: Arithmetic average\n\nSD: Measure of spread\n\n- Mathematically, $\\surd$ of averaged squared difference of an observation from the mean\n\n- Can be used to estimate the dispersion of a normally distributed _population_ \n\n- An estimate of the variability of the population from which the sample was drawn [@altman2005statistics]\n\n- About 95% of observations of any distribution usually fall within the 2 standard deviation limits\n\nAsymmetric data: SD$\\times$ 2  > Mean \n\n<aside>\nUse this rule-of-thumb when you don't have access to the raw data [@altman1996detecting]\n</aside>\n\nSE: Standard error is the SD of the sampling distribution of a statistic. \n\n- SE is used to infer about the range of plausible values for the *true*  (population) statistic. \n\n\n\n## Median & IQR\nMedian: Middle sorted value\n\n- Value such that around $\\frac{1}{2}$ of the values are below it and above it\n\n<aside>\nThis holds for truly continuous data\n</aside>\n\n\n- May not divide sample into $\\frac{1}{2}$ for \"clumped\" data\n\n- Mean is better than the median when the distribution (i) contains heavy ties, (ii) is limited or well-behaved\n\nIQR: Measure of spread\n\n- Defined by Quartile$_{1}$ ($Q_1$) and Quartile$_{3}$ ($Q_3$) \n\n- Interval containing the middle $\\frac{1}{2}$ of the sample \n\n\n\n\n## *P*-value\n- *P*-value = Probability value\n\n- Assuming that *H*$_{0}$ were true, what is the probability of obtaining a result (statistic) as or more extreme than our observed result? \n\n- If the  probability is low (often set at *P*<0.05), we have sufficient evidence to reject *H*$_{0}$ and accept *H*$_{1}$\n\n- If the  probability is low, we fail to reject *H*$_{0}$ but we do not speak of accepting *H*$_{0}$. The *P*-value provides evidence against a *null* hypothesis, **never** evidence for something. \n\n- The *P*-value is influenced by sample size and effect size. Classical statistical testing does not consider clinical significance: Clinical relevance cannot be concluded from small *P*-values.   \n\n<aside>\nUse this [link](https://www.youtube.com/embed/vemZtEM63GY) if the video doesn't play\n</aside>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/vemZtEM63GY\" frameborder=\"0\" allowfullscreen></iframe>\n\n<aside>\nIf you have understood the concept of P-values, please give credit to Josh Starmer - not me!\n</aside>\n\n\n \n\n## Confidence Interval\n- Range of values within which that the \"true\" (population) summary statistic (e.g., mean, correlation coefficient, or difference score) would plausibly lie. \n\nTo interpret a 95% confidence interval,\n\n- The wrong way: There is a 95% chance that the unknown true value lies within the interval \n\n- The rough way: We are 95% confident that the unknown true value lies within the interval\n\n- The exact way: If we were to repeat experiment many times and to compute, in each experiment, a confidence interval for the summary statistic, 95% of these CIs would contain the true (population) value. Or, this confidence interval is computed by an algorithm that has a 95% probability of including the true value in repeated sampling.\n\n\n<aside>\nUse this [link](https://www.youtube.com/embed/TqOeMYtOc1w) if the video doesn't play\n</aside>\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/TqOeMYtOc1w\" frameborder=\"0\" allowfullscreen></iframe>\n\n<aside>\nIf you have understood the concept of confidence interval, please give credit to [Josh Starmer](https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw) - not me!\n</aside>\n\n \n\n## Interpreting *P*-values and 95%CI. \n<style>\ndiv.blue { background-color:#e6f0ff; border-radius: 0px; padding: 0px;}\n</style>\n<div class = \"blue\">\nIn general, the only way that a large P -value can be interpreted is for example \"The study did not provide sufficient evidence for an effect.\" One cannot say \"Because *P* = 0.70, we conclude the drug has no effect\". Only when the corresponding confidence interval excludes both clinically significant benefit and harm can one make such a conclusion. A large *P*-value by itself merely means that a higher sample size is required to allow conclusions to be drawn\n</div>\n\n<aside>\nGo to Frank Harrell's [DataMethods](https://discourse.datamethods.org/t/author-checklist/3407) for more details \n</aside>\n\n<br>    \n \n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/PPD8lER8ju4\" frameborder=\"0\" allowfullscreen></iframe>\n\n<aside>\nAdriene Hill from [Crash Course](https://thecrashcourse.com/courses/statistics) explains how to interpret \"large\" P-values\n</aside>\n\n\n## *P-value*, Point Estimate, 95% CI  \nThe *P*-value   \nThis quantifies the evidence for a non-zero between-group difference. A large *P*-value, by itself, only suggests that we have insufficient evidence for a between-group difference. \n\n<aside>\nRemember: absence of evidence may not represent evidence of absence. \n</aside>\n\nThe observed mean difference    \nAppraise this estimate against the MCID value.     \n*What we do know*: An individual-level MCID is almost always [**greater** than a group-level MCID](https://rapm.bmj.com/content/early/2022/03/31/rapm-2021-103331)     \n*What we do not know*: how much greater is **greater**? \n\n<aside>\nIn the absence of data, Yonghao suggests 0.5*individual-level MCID. But how much we can trust this estimate?\n</aside>\n\n\nThe 95% CI      \n(Very) Loosely speaking, this represents the range of plausible values for the true between-group differences.   \nWide CI: there is great uncertainty about the true between-group differences   \nNarrow CI: there is little uncertainty about the true between-group differences. When there is little uncertainty, the finding is almost always clinically relevant.\n\n<aside>\nHence, it is possible to have a finding that is statistically non-significant but highly clinically relevant. \n</aside>\n\n\nExample      \nFindings   \nWe observed a between-group difference of 6 points on the ODI, with a corresponding *P*-value of 0.01 and a 95%CI of 1 to 12 points\n\nAppraisal     \nThe *P*-value: We have evidence of a non-zero between-group difference   \nThe Point estimate: If we are willing to assume a group-level MCID of 6 points, the observed between-group difference is probably clinically meaningful    \nThe 95% CI: The wide 95%CI includes clinically trivial values; hence, there is uncertainty about the true between-group difference \n\n<aside>\nWe need to consider whether the 95%CI includes/excludes clinically trivial results. \n</aside>\n\n\nInference   \nWhilst we have evidence that two groups are different on the ODI and the observed between-group difference appeared to be clinically meaningful, there is still uncertainty about the true between-group differences. \n\n\n\n::: l-body\n| Findings              | Interpretation                                    |\n|-----------------------|------------------------------------------------|\n| P<0.05  | Evidence of a (non-zero) treatment difference/effect                |\n| P>0.05  | Insufficient/No evidence of association (â‰  evidence of no treatment difference)[^1]           |\n| (1) P<0.05; 95% CIs exclude trivial effects | Evidence of a clinically meaningful treatment difference|\n| (2) P<0.05; 95% CIs exclude meaningful effects | Evidence of a treatment diff; however, this difference is not clinically meaningful|\n| (3) P<0.05; 95% CIs include trivial + meaningful effects | Cannot exclude non-clinically meaningful treatment difference|\n| (4) P>0.05; 95% CIs exclude meaningful effects  | (Possibly) Evidence of no treatment difference       |\n| (5) P>0.05; 95% CI limits include meaningful effects  | CI indicates a wide range of plausible true treatment differences (inconclusive finding as all scenarios are possible)           |\n| (6) P>0.05; 95% CI limits  include trivial + meaningful effects  | No evidence of treatment difference, however, we cannot exclude clinically important difference           |\n:::\n\n[^1]: Beware of making the \"Absence of Evidence is NOT Evidence of Absence\" fallacy\n\n\nHawkins and Samuels [JAMA article](https://jamanetwork.com/journals/jama/article-abstract/2786522) describes how to use 95%CIs to appraise non-significant results \n<br> \n![ci_ns](ci_ns.jpg){width=500}\n\nInterestingly, the authors wrote:\n\n> Although CIs can be used to enhance the interpretation of a study, they have a number of limitations. For example, a 95%CI does not have a 95% probability of containing the true value of interest (eg, the true treatment effect), **even though it is commonly described that way**. Creating an interval that does have a specified probability of containing the true value requires a Bayesian analysis  \n>\n> <footer>--- Hawkins and Samuels</footer>\n\n\n\n\n## Bayesian Statistics\n- A branch of statistics that (i) uses Bayes Theorem and (ii) doesn't use P-values and generally does not test hypotheses. \n\n- Bayesian Statistics requires one to formally specify a probability distribution encapsulating the prior knowledge about, say, a treatment effect. \n\n<aside>\nThis section is taken from Frank Harrell's [glossary](http://hbiostat.org/glossary/) \n</aside>\n\n- The state of prior knowledge can be specified as $no$ knowledge\" by using a flat distribution, although this can lead to\nwild and nonsensical estimates. \n- Once the prior distribution is specified, the data are used to modify the prior state of knowledge to obtain the post-experiment state of knowledge. \n- Final probabilities computed in the Bayesian framework are probabilities of various treatment effects. \n\n\n### Comparing the 2 schools of thought\n::: l-body\n| Bayesian                           | Frequentist                                    |\n|------------------------------------|------------------------------------------------|\n| Bayesian statistics aims to uncover the unknown treatment effect by providing evidence for all its possible values |                                        Frequentist statistics aims to uncover the unknown treatment effect by providing evidence that it is not the null value|\n| In Bayesian statistics, one specifies the prior distribution for the unknown treatment effect  and uses a data generation process to estimate the conditional data likelihood. For a given (single) data-set, Bayesian statistics provides probabilities for all possible values of the treatment effect|                              In Frequentist statistics, one specifies a null hypothesis/value about the unknown treatment effect and uses a data generation process to make infinite replications of the data. For a given null hypothesis, Frequentist statistics provides probabilities of getting studies/datasets with more extreme results than the ones that we observe. In other words, conditional on there being no treatment efficacy and no harm, the P-value is the proportion of studies with results more extreme than the ones we have\n:::\n\n\n\n<style>\ndiv.blue { background-color:#e6f0ff; border-radius: 0px; padding: 0px;}\n</style>\n<div class = \"blue\">\n\nProf Frank Harrell has provided a more detailed side-by-side [comparison](https://hbiostat.org/proj/covid19/statdesign.html#bftable)\n\n</div>\n\n\n\n\n### Bayes Theorem\nIn my opinion, [3Blue1Brown](https://www.3blue1brown.com/) explains this the best\n\n<br>    \n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/HZGCoVF3YvM\" frameborder=\"0\" allowfullscreen>\n</iframe>\n\n<br>    \n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/lG4VkPoG3ko\" frameborder=\"0\" allowfullscreen>\n</iframe>\n\n\n<aside>\nGo to [Better Explained](https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/) for more details \n</aside>\n\n\n### Consideration\n- Bayesian methods provide direct, simply-stated probabilities of various treatment effects. \n\n- The price of being able to compute probabilities of various treatment effects is the necessity of specifying a prior\ndistribution to anchor the calculations.\n\n- Tutorials for healthcare professionals \n    - [Baldwin and Larson 2017](https://pubmed.ncbi.nlm.nih.gov/28081861/) \n    - [Heino et al 2018](https://pubmed.ncbi.nlm.nih.gov/34040821/)\n    - Frank Harrell's incredibly useful [hbiostat pages](https://hbiostat.org/bayes/)\n\n    \n\n\n\n## To Note {.appendix}\nA comprehensive glossary of terms can be found [here](http://hbiostat.org/glossary/)\n\nStatistical problems to avoid when reading an article can be found [here](https://discourse.datamethods.org/t/author-checklist/3407) \n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}